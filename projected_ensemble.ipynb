{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import functools as ft\n",
    "from scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projected ensemble simulation\n",
    "\n",
    "We define a Hamiltonian following [Cotler et al.](https://doi.org/10.1103/PRXQuantum.4.010311). It is a one-dimensional spin chain with single-site mixed field terms and nearest neighbour interaction terms, without periodic boundary conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time evolution: parameters, Hamiltonian, initial state\n",
    "\n",
    "To simulate the dynamics use a naive approach:\n",
    "- State is a vector, Hamiltonian is a matrix\n",
    "- Exponentiate Hamiltonian to get time evolution operator\n",
    "- Matvec multiplication to get final state $\\ket{\\Psi} = U \\ket{\\Psi_0}$\n",
    "\n",
    "With my laptop this is only achievable for $N_A = 1$ and $N_B$ up to about $9$, which hopefully is sufficiently large to get a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hamiltonian: Quantum Ising spin with mixed fields (QIMF)\n",
    "\n",
    "# Parameters (as per Cotler et al.)\n",
    "# h_x = 0.8090\n",
    "# h_y = 0.9045\n",
    "# J = 1\n",
    "# N_A = 2\n",
    "# N_B = 6\n",
    "# N = N_A + N_B\n",
    "\n",
    "# Pauli matrices\n",
    "sx = np.array([[0,1],[1,0]]) ;  sy = np.array([[0,-1j],[1j,0]])\n",
    "\n",
    "def QIMF(N_A, N_B, h_x, h_y, J):\n",
    "    N = N_A + N_B\n",
    "\n",
    "    # Single site term\n",
    "    H1 = h_x * sx + h_y * sy\n",
    "    # Interaction term\n",
    "    H2 = J * np.kron(sx,sx)\n",
    "\n",
    "    # Hamiltonian as a matrix\n",
    "    H = np.zeros((2**N,2**N),dtype='complex128')\n",
    "    for i in range(N):\n",
    "        H += ft.reduce(np.kron, [np.identity(2**i), H1, np.identity(2**(N-i-1))])\n",
    "    for i in range(N-2):\n",
    "        H += ft.reduce(np.kron, [np.identity(2**i), H2, np.identity(2**(N-i-2))])\n",
    "    \n",
    "    return H\n",
    "\n",
    "def Psi_initial(N_A, N_B):\n",
    "    # Initial state: all |0>\n",
    "    N = N_A + N_B\n",
    "    Psi0 = np.zeros(2**N)\n",
    "    Psi0[0] = 1\n",
    "    return Psi0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraxting projected ensemble\n",
    "\n",
    "Next, a function to get the projected ensemble as a list, in the form [ [p_1, state_1], ... , [p_N, state_N] ], with the states numpy arrays in computational basis for subsystem $A$. We take $A$ to be the first $N_A$ qubits. I have made two functions:\n",
    "- Firstly, using projectors and looping over all measurement outcomes on B, as you would do it by hand from a generic $\\ket{\\Psi}$;\n",
    "- Secondly, realising that in the way $\\ket{\\Psi}$ is stored as coefficients in the computational basis, the coefficients can pretty much be read off without need for projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, getting a projected ensemble from the most literal, obvious way: by defining projectors for each measurement outcome\n",
    "\n",
    "def Get_PrEns_slow(Psi, N_A, N_B):\n",
    "    # Define empty ensemble\n",
    "    PrEns = np.empty((2**N_B, 2)).tolist()\n",
    "\n",
    "    # Loop over |z_B>, make projectors\n",
    "    for i in range(2**N_B):\n",
    "        z_B = np.zeros(2**N_B)\n",
    "        z_B[i] = 1\n",
    "        P = np.kron(np.identity(2**N_A), np.outer(z_B,z_B))\n",
    "\n",
    "        Psi_zB = P @ Psi\n",
    "\n",
    "        # Pick out probability (norm), then normalise, then get PsiA\n",
    "        PrEns[i][0] = np.linalg.norm(Psi_zB) ** 2\n",
    "        Psi_zB /= np.linalg.norm(Psi_zB)\n",
    "        PrEns[i][1] = Psi_zB.reshape(2**N_A, 2**N_B)[:,i]\n",
    "    \n",
    "    return PrEns\n",
    "\n",
    "# Then I realised that with the way things are stored we can just read it off\n",
    "\n",
    "def Get_PrEns(Psi, N_A, N_B):\n",
    "    PrEns = np.empty((2**N_B, 2)).tolist()\n",
    "\n",
    "    for i in range(2**N_B):\n",
    "        PsiA = Psi.reshape(2**N_A, 2**N_B)[:,i]\n",
    "        PrEns[i][0] = np.linalg.norm(PsiA) ** 2\n",
    "        PrEns[i][1] = PsiA / np.linalg.norm(PsiA)\n",
    "    \n",
    "    return PrEns\n",
    "\n",
    "# A quick check confirms these give the same results, so no outer products / matrix vector multiplication is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moments\n",
    "\n",
    "Next: get the moments from the distributions. These are straightforwardly described as either $d \\times \\cdots \\times d$ rank-$2k$ tensors or as $d^k \\times d^k$ matrices. Here I use matrices for convenience.\n",
    "\n",
    "Firstly, some functions that give me moments of the Haar ensemble from the permutation-representation formula in [Cotler et al.](https://doi.org/10.1103/PRXQuantum.4.010311) appendix A. I have done this for $k = 1, 2, 3$ 'by hand', but for general dimension $d$ of the Hilbert space $\\mathcal{H}_A$. Not sure if it can easily be done for general $k$.\n",
    "\n",
    "Secondly, a function that gives me moments for a projected ensemble as those extracted from the quenched states.\n",
    "\n",
    "As a test, I constructed moments from the minimal $3$-design with $d = 2$ (positive and negative eigenvalue spin eigenstates in the three orthogonal directions), and these gave the same results as the functions generating the Haar moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 3 moments of the Haar ensemble\n",
    "\n",
    "def rho_1_Haar(d):\n",
    "    rho_1 = np.identity(d, dtype='complex128') / d\n",
    "    return rho_1\n",
    "\n",
    "def rho_2_Haar(d):\n",
    "    rho_2 = np.zeros((d**2,d**2), dtype='complex128')\n",
    "    \n",
    "    # Identity\n",
    "    rho_2 += np.identity(d**2, dtype='complex128')\n",
    "\n",
    "    # Swap\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            ket_i = np.zeros(d)\n",
    "            ket_i [i] = 1\n",
    "            ket_j = np.zeros(d)\n",
    "            ket_j [j] = 1\n",
    "\n",
    "            ket_ij = np.kron(ket_i, ket_j)\n",
    "            ket_ji = np.kron(ket_j, ket_i)\n",
    "\n",
    "            rho_2 += np.outer(np.conjugate(ket_ji), ket_ij)\n",
    "        \n",
    "\n",
    "    return rho_2 / (d * (d+1) )\n",
    "\n",
    "def rho_3_Haar(d):\n",
    "    rho_3 = np.zeros((d**3,d**3), dtype='complex128')\n",
    "\n",
    "    # Identity\n",
    "    rho_3 += np.identity(d**3, dtype='complex128')\n",
    "\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                ket_i = np.zeros(d)\n",
    "                ket_i[i] = 1\n",
    "                ket_j = np.zeros(d)\n",
    "                ket_j[j] = 1\n",
    "                ket_k = np.zeros(d)\n",
    "                ket_k[k] = 1\n",
    "\n",
    "                ket_ijk = ft.reduce(np.kron, [ket_i, ket_j, ket_k])\n",
    "\n",
    "                # swaps\n",
    "                ket_jik = ft.reduce(np.kron, [ket_j, ket_i, ket_k])\n",
    "                ket_ikj = ft.reduce(np.kron, [ket_i, ket_k, ket_j])\n",
    "                ket_kji = ft.reduce(np.kron, [ket_k, ket_j, ket_i])\n",
    "                rho_3 += np.outer(np.conjugate(ket_jik), ket_ijk)\n",
    "                rho_3 += np.outer(np.conjugate(ket_ikj), ket_ijk)\n",
    "                rho_3 += np.outer(np.conjugate(ket_kji), ket_ijk)\n",
    "\n",
    "                # 3-cycles\n",
    "                ket_jki = ft.reduce(np.kron, [ket_j, ket_k, ket_i])\n",
    "                ket_kij = ft.reduce(np.kron, [ket_k, ket_i, ket_j])\n",
    "                rho_3 += np.outer(np.conjugate(ket_jki), ket_ijk)\n",
    "                rho_3 += np.outer(np.conjugate(ket_kij), ket_ijk)\n",
    "\n",
    "    return rho_3 / (d * (d+1) * (d+2))\n",
    "\n",
    "# Moments from projected ensemble\n",
    "\n",
    "def rho_PrEns(PrEns, k):\n",
    "    \n",
    "    d = np.size(PrEns[0][1])\n",
    "    rho_k = np.zeros((d**k, d**k), dtype='complex128')\n",
    "\n",
    "    for i in range(len(PrEns)):\n",
    "        p_i = PrEns[i][0]\n",
    "        state_i = PrEns[i][1]\n",
    "        k_copies = ft.reduce(np.kron, [state_i for i in range(k)])\n",
    "\n",
    "        rho_k += p_i * np.outer(np.conjugate(k_copies), k_copies)\n",
    "    \n",
    "    return rho_k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "\n",
    "Now it's time to just do the whole thing. Simulate, find the projected ensembles and the moments, and output. Let's get all the data in one long run and store in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# We're storing data: times and projected ensembles for two Hamiltonians.\n",
    "times = np.linspace(0.1,25,200)\n",
    "Ch_Dist = np.empty((5,3,np.size(times)))\n",
    "Int_Dist = np.empty((5,3,np.size(times)))\n",
    "\n",
    "# Fixed variables\n",
    "N_A = 2\n",
    "h_y = 0.9045\n",
    "J = 1\n",
    "\n",
    "d = 2**N_A\n",
    "rho_1 = rho_1_Haar(d)\n",
    "rho_2 = rho_2_Haar(d)\n",
    "rho_3 = rho_3_Haar(d)\n",
    "\n",
    "N_Bs = [4,5,6,7,8]\n",
    "\n",
    "for i, N_B in enumerate(N_Bs):\n",
    "\n",
    "    h_x = 0.8090\n",
    "    H = QIMF(N_A, N_B, h_x, h_y, J)\n",
    "    Psi0 = Psi_initial(N_A, N_B)\n",
    "\n",
    "    for j, t in enumerate(times):\n",
    "        U = expm(-t * 1j * H)\n",
    "        Psi = U @ Psi0\n",
    "        PrEns = Get_PrEns(Psi, N_A, N_B)\n",
    "        \n",
    "        rho_1_sim = rho_PrEns(PrEns, 1)\n",
    "        dist_1 = np.linalg.norm(rho_1 - rho_1_sim, 'nuc') / 2\n",
    "        Ch_Dist[i,0,j] = dist_1\n",
    "\n",
    "        rho_2_sim = rho_PrEns(PrEns, 2)\n",
    "        dist_2 = np.linalg.norm(rho_2 - rho_2_sim, 'nuc') / 2\n",
    "        Ch_Dist[i,1,j] = dist_2\n",
    "\n",
    "        rho_3_sim = rho_PrEns(PrEns, 3)\n",
    "        dist_3 = np.linalg.norm(rho_3 - rho_3_sim, 'nuc') / 2\n",
    "        Ch_Dist[i,2,j] = dist_3\n",
    "\n",
    "    \n",
    "    h_x = 0\n",
    "    H = QIMF(N_A, N_B, h_x, h_y, J)\n",
    "    Psi0 = Psi_initial(N_A, N_B)\n",
    "\n",
    "    for j, t in enumerate(times):\n",
    "        U = expm(-t * 1j * H)\n",
    "        Psi = U @ Psi0\n",
    "        PrEns = Get_PrEns(Psi, N_A, N_B)\n",
    "        \n",
    "        rho_1_sim = rho_PrEns(PrEns, 1)\n",
    "        dist_1 = np.linalg.norm(rho_1 - rho_1_sim, 'nuc') / 2\n",
    "        Int_Dist[i,0,j] = dist_1\n",
    "\n",
    "        rho_2_sim = rho_PrEns(PrEns, 2)\n",
    "        dist_2 = np.linalg.norm(rho_2 - rho_2_sim, 'nuc') / 2\n",
    "        Int_Dist[i,1,j] = dist_2\n",
    "\n",
    "        rho_3_sim = rho_PrEns(PrEns, 3)\n",
    "        dist_3 = np.linalg.norm(rho_3 - rho_3_sim, 'nuc') / 2\n",
    "        Int_Dist[i,2,j] = dist_3\n",
    "\n",
    "\n",
    "np.savez('Trace_distances', times=times, Ch_Dist = Ch_Dist, Int_Dist = Int_Dist)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
